{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Learning of Posteriors for Gaussian Mixture Model using Mixture of Discrete Normalizing Flows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian mixture model (GMM) is an example of a model with both discrete and continuous latent variables.\n",
    "We train it using Variational EM, i.e., by alternating between optimization of continuous (M-step) and discrete (E-step) variables. In our implementation, we replace E-step with gradient-based optimization of an approximation to clustersâ€™ posterior allocations using MDNF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import distributions as tfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.2.0', '0.9.0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__, tfp.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.2.1', '0.21.2')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "import sklearn\n",
    "scipy.__version__, sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../mdnf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aux\n",
    "import time_profiling\n",
    "\n",
    "import base_constructors\n",
    "import flows_mixture\n",
    "import inference\n",
    "import gmvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='%(relativeCreated)6d %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4239 parsing: <-f>\n"
     ]
    }
   ],
   "source": [
    "# can be run as a script with args in format KEY=VAL,KEY=[STRVAL],...\n",
    "args = aux.parse_script_args() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4261 Results output file: GMVI_p_5_1.csv\n"
     ]
    }
   ],
   "source": [
    "SEED = args.get(\"SEED\", 1)\n",
    "\n",
    "DATA = args.get(\"DATA\", \"ARTIFICIAL\")  # \"GOOGLE\" / \"TRIP\" / \"ARTIFICIAL\"\n",
    "\n",
    "# If data set to ARTIFICIAL\n",
    "NC = args.get(\"NC\", 3) # how many clusters\n",
    "M1 = args.get(\"CLUSTER_SIZE\", 100) # nsamples per cluster in data\n",
    "R = args.get(\"R\", 2.0) # distance of clusters' centers to 0\n",
    "\n",
    "# \"D(0.01)\" / \"D(0.1)\" / \"D(1)\" / \"D(10)\"\n",
    "BASE_SPECIFICATION = args.get(\"BASE_SPECIFICATION\", \"p\") # base distribution type\n",
    "\n",
    "B = args.get(\"B\", 5) # how many flows in mixture\n",
    "FLOW_TYPE = args.get(\"FLOW_TYPE\", \"FU\")  # flows' type\n",
    "FACTORIZED_BASE = bool(args.get(\"FACTORIZED_BASE\", 1)) # 1 means factorized flows (assume independence)\n",
    "\n",
    "# number of components (=how many clusters to fit), \n",
    "K = args.get(\"K\", 3) # None means = true number of clusters (only if available)\n",
    "FLOWS_K = args.get(\"K\", K) # K used in flows \n",
    "\n",
    "INIT = args.get(\"INIT\", \"random\") # inifialization: \"random\"/\"kmeans\"\n",
    "\n",
    "# outer loop:\n",
    "MIN_NITER = args.get(\"MIN_NITER\", 10)\n",
    "MAX_NITER = args.get(\"MAX_NITER\", 100)\n",
    "NOIMPROV_NITER = args.get(\"NOIMPROV_NITER\", 10) # stop if no improvement in niters\n",
    "EVAL_BATCH_SIZE = args.get(\"EVAL_BATCH_SIZE\", 10240) # how many data pts per minibatch\n",
    "EVAL_NSAMPLES = args.get(\"EVAL_NSAMPLES\", 100) # how many samples to estimate ELBO (only if sampling used)\n",
    "\n",
    "# inner E-step loop:\n",
    "E_NITER = args.get(\"E_NITER\", 1000) # how many iterations in E-step\n",
    "E_NOIMPROV_NITER = args.get(\"E_NOIMPROV_NITER\", 100) # stop if no improvement in niters\n",
    "E_MIN_NITER = args.get(\"E_MIN_NITER\", 0)\n",
    "E_BATCH_SIZE = args.get(\"E_BATCH_SIZE\", 10240) # how many data pts per minibatch\n",
    "E_DROP_REMAINDER = bool(args.get(\"E_DROP_REMAINDER\", 0))\n",
    "NSAMPLES = args.get(\"NSAMPLES\", 100) # how many samples for E-step\n",
    "E_HYBRID_ELBO = bool(args.get(\"E_HYBRID_ELBO\", 1))\n",
    "\n",
    "INFERENCE = args.get(\"INFERENCE\", 0) # 0=VIF, 1=BVIF\n",
    "OPTIMIZER = args.get(\"OPTIMIZER\", \"RMS\")\n",
    "LR = args.get(\"LR\", 0.1)\n",
    "\n",
    "# Temperature hyperparameter\n",
    "BASE_TEMP = args.get(\"BASE_TEMP\", 10.0)\n",
    "ANNEAL_RATE = args.get(\"ANNEAL_RATE\", 0.01)\n",
    "E_ANNEAL_RATE = args.get(\"E_ANNEAL_RATE\", 0.01)\n",
    "MIN_TEMP = args.get(\"MIN_TEMP\", 0.001)\n",
    "\n",
    "CLUSTER_MIN_WEIGHT = 1.0 # min probability mass to assume that cluster hasn't disappeared\n",
    "VISUALIZATIONS = False # plot assignments\n",
    "\n",
    "# Where to store results\n",
    "OUT = args.get(\"OUT\", \"GMVI_%s_%s_%s.csv\" % \\\n",
    "               (BASE_SPECIFICATION, B, SEED))\n",
    "logger.info(\"Results output file: %s\" % OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4273 CONFIGURATION:\n",
      " SEED=1\n",
      " DATA=ARTIFICIAL\n",
      " NUM_CLUSTERS=3\n",
      " CLUSTERS_SIZE=100\n",
      " CLUSTERS_DIST=2.0\n",
      " BASE_SPECIFICATION=p\n",
      " FACTORIZED_BASE=1\n",
      " B=5\n",
      " K=3\n",
      " FLOW_TYPE=FU\n",
      " E_HYBRID_ELBO=True\n",
      " INFERENCE=0\n",
      " OPTIMIZER=RMS\n",
      " LR=0.1\n",
      " NSAMPLES=100\n",
      " EVAL_BATCH_SIZE=10240\n",
      " EVAL_NSAMPLES=100\n",
      " INIT=random\n",
      " MIN_NITER=10\n",
      " MAX_NITER=100\n",
      " NOIMPROV_NITER=10\n",
      " E_MIN_NITER=0\n",
      " E_NITER=1000\n",
      " E_NOIMPROV_NITER=100\n",
      " E_BATCH_SIZE=10240\n",
      " E_DROP_REMAINDER=False\n",
      " BASE_TEMP=10.0\n",
      " ANNEAL_RATE=0.01\n",
      " E_ANNEAL_RATE=0.01\n",
      " MIN_TEMP=0.001\n"
     ]
    }
   ],
   "source": [
    "# Store & print configuration\n",
    "CFG =      [SEED, DATA, NC, M1, R,\n",
    "            BASE_SPECIFICATION, int(FACTORIZED_BASE), B, K, FLOW_TYPE, \n",
    "            E_HYBRID_ELBO, INFERENCE, OPTIMIZER, LR, \n",
    "            NSAMPLES, EVAL_BATCH_SIZE, EVAL_NSAMPLES,\n",
    "            INIT, MIN_NITER, MAX_NITER, NOIMPROV_NITER,\n",
    "            E_MIN_NITER, E_NITER, E_NOIMPROV_NITER, E_BATCH_SIZE, E_DROP_REMAINDER,\n",
    "            BASE_TEMP, ANNEAL_RATE, E_ANNEAL_RATE, MIN_TEMP,]\n",
    "CFGNAMES = [\"SEED\", \"DATA\", \"NUM_CLUSTERS\", \"CLUSTERS_SIZE\", \"CLUSTERS_DIST\",\n",
    "            \"BASE_SPECIFICATION\", \"FACTORIZED_BASE\", \"B\", \"K\", \"FLOW_TYPE\", \n",
    "            \"E_HYBRID_ELBO\", \"INFERENCE\", \"OPTIMIZER\", \"LR\", \n",
    "            \"NSAMPLES\", \"EVAL_BATCH_SIZE\", \"EVAL_NSAMPLES\",\n",
    "            \"INIT\", \"MIN_NITER\", \"MAX_NITER\", \"NOIMPROV_NITER\", \n",
    "            \"E_MIN_NITER\", \"E_NITER\", \"E_NOIMPROV_NITER\", \"E_BATCH_SIZE\", \"E_DROP_REMAINDER\",\n",
    "            \"BASE_TEMP\", \"ANNEAL_RATE\", \"E_ANNEAL_RATE\", \"MIN_TEMP\",]            \n",
    "\n",
    "logger.info(\"CONFIGURATION:\\n \"+\"\\n \".join(\"%s=%s\" % (name, val) \n",
    "                                     for name, val in zip(CFGNAMES, CFG)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data selection / generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA.upper().startswith(\"ART\"):\n",
    "    np.random.seed(0)\n",
    "\n",
    "    clusters = []\n",
    "    cluster_nos = []\n",
    "    for cno, angle in enumerate(np.arange(0, 2*np.pi, 2*np.pi / NC)):\n",
    "        if cno>=NC: break\n",
    "        x, y = R*np.sin(angle), R*np.cos(angle)\n",
    "\n",
    "        c1 = np.random.normal(size=(M1, 2))\n",
    "        c1 += np.array([x, y])\n",
    "        clusters.append(c1)\n",
    "        cluster_nos.append(np.ones(M1)*cno)\n",
    "    x_train = np.vstack(clusters)\n",
    "    z_train = np.hstack(cluster_nos).astype(int)\n",
    "    \n",
    "elif DATA.upper().startswith(\"TRIP\"):\n",
    "    d = pd.read_csv(\"datasets/tripadvisor_review.csv.gz\", compression='gzip')    \n",
    "    FEATURES = ['Category 1', 'Category 2', 'Category 3', 'Category 4',\n",
    "                'Category 5', 'Category 6', 'Category 7', 'Category 8', 'Category 9',\n",
    "                'Category 10']\n",
    "    x_train = d[FEATURES].to_numpy().astype('float64')\n",
    "    z_train = np.zeros(x_train.shape[0])    \n",
    "\n",
    "elif DATA.upper().startswith(\"GOOGLE\"):\n",
    "    d = pd.read_csv(\"datasets/google_review_ratings_clean.csv.gz\", compression=\"gzip\")    \n",
    "    FEATURES = ['Category 1', 'Category 2', 'Category 3', 'Category 4',\n",
    "           'Category 5', 'Category 6', 'Category 7', 'Category 8', 'Category 9',\n",
    "           'Category 10', 'Category 11', 'Category 12', 'Category 13',\n",
    "           'Category 14', 'Category 15', 'Category 16', 'Category 17',\n",
    "           'Category 18', 'Category 19', 'Category 20', 'Category 21',\n",
    "           'Category 22', 'Category 23', 'Category 24']\n",
    "    x_train = d[FEATURES].to_numpy().astype('float64')\n",
    "    z_train = np.zeros(x_train.shape[0])        \n",
    "    \n",
    "else:\n",
    "    raise ValueError(\"Wrong DATA=%s set!\" % DATA)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4298 x_train=(300, 2) clusters=Counter({0: 100, 1: 100, 2: 100})\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"x_train=%s clusters=%s\" % (x_train.shape, collections.Counter(z_train)))\n",
    "if K is None:\n",
    "    K = len(collections.Counter(z_train))\n",
    "    logger.info(\"assigning K := %s\" % K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PDF visualization grid\n",
    "x0, x1 = np.meshgrid(np.linspace(-R*2, R*2, 100), np.linspace(-R*2, R*2, 100))\n",
    "x = np.array([x0, x1]).reshape(2, -1).T\n",
    "\n",
    "try: # fails when run on a cluster\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    plt.scatter(x_train[:, 0], x_train[:, 1], c=z_train)\n",
    "    plt.xlim(-R*2, R*2, 100)\n",
    "    plt.ylim(-R*2, R*2, 100)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    logger.warn(\"Plotting failed: %s\" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accurracy of clustering as classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(allocations, true_zs):\n",
    "    \"\"\" Returns clustering accurracy where assigned cluster label:=dominant label. \"\"\"\n",
    "    total_num_errors = 0\n",
    "    clusters = np.argmax(allocations, 1)\n",
    "    for cluster_no in set(clusters):\n",
    "        # match cluster by selecting the most popular one from the true ones\n",
    "        true_clusters = true_zs[clusters==cluster_no]\n",
    "        true_clusters_counts = collections.Counter(true_clusters)   \n",
    "        true_cluster = sorted(true_clusters_counts.items(), key=lambda kv: -kv[1])[0][0] \n",
    "        num_errors = len(true_clusters) - true_clusters_counts[true_cluster]\n",
    "        total_num_errors += num_errors\n",
    "        #logger.debug(\"[acc] cluster no=%s is mapped to true cluster no=%s num_errors=%s/%s\"\\\n",
    "        #            % (cluster_no, true_cluster, num_errors, len(true_clusters)))\n",
    "    #logger.debug(\"[acc] total_num_errors=%s / %s\" % (total_num_errors, len(true_zs)))\n",
    "    return (len(true_zs)-total_num_errors) / len(true_zs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: closed-form VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgmm0 = gmvi.VariationalGaussianMixtureELBO(n_components=K, elbo_nsamples=EVAL_NSAMPLES,\n",
    "                                           initialization=INIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing results with a callback functions\n",
    "\n",
    "RESULTS = []        \n",
    "COLS = [\"wall_time\", \"time\", \"iteration\", \"temp\", \"loss\", \"kl\", \"accurracy\", \"cdists\", \"rec_nclusters\"]\n",
    "\n",
    "start_time = time.time()\n",
    "def callback_iter(status, step_no, elbo):  \n",
    "    accurracy = acc(status.r, z_train)\n",
    "    homogenity = sklearn.metrics.homogeneity_score(z_train, np.argmax(status.r, 1))\n",
    "    recovered_nclusters = np.sum(np.sum(status.r, 0)>CLUSTER_MIN_WEIGHT)\n",
    "    wall_time = time.time()-start_time\n",
    "\n",
    "    RESULTS.append( (wall_time, wall_time,  \n",
    "                     step_no, -1, \n",
    "                     float(-elbo), -1, accurracy,\n",
    "                     0., recovered_nclusters,) )    \n",
    "    \n",
    "    logger.info(\"[VGM-ELBO.fit][%.2fs] iter=%s ELBO=%.2f acc=%.4f homo=%.4f\" % \\\n",
    "                (wall_time, step_no, elbo, accurracy, homogenity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4535 [VGM-ELBO.fit][0.04s] iter=-1 ELBO=-196974.37 acc=0.3667 homo=0.0035\n",
      "  4555 [VGM-ELBO.fit][0.06s] iter=0 ELBO=-1297.17 acc=0.5300 homo=0.1876\n",
      "  4574 [VGM-ELBO.fit][0.08s] iter=1 ELBO=-1220.81 acc=0.5767 homo=0.2710\n",
      "  4592 [VGM-ELBO.fit][0.10s] iter=2 ELBO=-1206.34 acc=0.6000 homo=0.3472\n",
      "  4609 [VGM-ELBO.fit][0.12s] iter=3 ELBO=-1198.27 acc=0.6033 homo=0.3554\n",
      "  4622 [VGM-ELBO.fit][0.13s] iter=4 ELBO=-1193.78 acc=0.6200 homo=0.4005\n",
      "  4637 [VGM-ELBO.fit][0.15s] iter=5 ELBO=-1191.65 acc=0.6233 homo=0.4110\n",
      "  4655 [VGM-ELBO.fit][0.16s] iter=6 ELBO=-1190.64 acc=0.6133 homo=0.3737\n",
      "  4670 [VGM-ELBO.fit][0.18s] iter=7 ELBO=-1189.97 acc=0.6133 homo=0.3737\n",
      "  4683 [VGM-ELBO.fit][0.19s] iter=8 ELBO=-1189.35 acc=0.6133 homo=0.3737\n",
      "  4701 [VGM-ELBO.fit][0.21s] iter=9 ELBO=-1188.66 acc=0.6100 homo=0.3657\n",
      "  4720 [VGM-ELBO.fit][0.23s] iter=10 ELBO=-1187.82 acc=0.6100 homo=0.3657\n",
      "  4744 [VGM-ELBO.fit][0.25s] iter=11 ELBO=-1186.73 acc=0.6100 homo=0.3657\n",
      "  4765 [VGM-ELBO.fit][0.27s] iter=12 ELBO=-1185.30 acc=0.6100 homo=0.3657\n",
      "  4777 [VGM-ELBO.fit][0.28s] iter=13 ELBO=-1183.49 acc=0.6100 homo=0.3657\n",
      "  4793 [VGM-ELBO.fit][0.30s] iter=14 ELBO=-1181.97 acc=0.6100 homo=0.3657\n",
      "  4814 [VGM-ELBO.fit][0.32s] iter=15 ELBO=-1181.64 acc=0.6100 homo=0.3657\n",
      "  4831 [VGM-ELBO.fit][0.34s] iter=16 ELBO=-1181.63 acc=0.6100 homo=0.3657\n",
      "  4847 [VGM-ELBO.fit][0.35s] iter=17 ELBO=-1181.63 acc=0.6100 homo=0.3657\n",
      "  4862 [VGM-ELBO.fit][0.37s] iter=18 ELBO=-1181.63 acc=0.6133 homo=0.3737\n",
      "  4875 [VGM-ELBO.fit][0.38s] iter=19 ELBO=-1181.63 acc=0.6133 homo=0.3737\n",
      "  4887 [VGM-ELBO.fit][0.40s] iter=20 ELBO=-1181.63 acc=0.6133 homo=0.3737\n",
      "  4901 [VGM-ELBO.fit][0.41s] iter=21 ELBO=-1181.63 acc=0.6133 homo=0.3737\n",
      "  4917 [VGM-ELBO.fit][0.42s] iter=22 ELBO=-1181.63 acc=0.6133 homo=0.3737\n",
      "  4935 [VGM-ELBO.fit][0.44s] iter=23 ELBO=-1181.63 acc=0.6133 homo=0.3737\n",
      "  4953 [VGM-ELBO.fit][0.46s] iter=24 ELBO=-1181.63 acc=0.6133 homo=0.3737\n",
      "  4971 [VGM-ELBO.fit][0.48s] iter=25 ELBO=-1181.63 acc=0.6133 homo=0.3737\n",
      "  4993 [VGM-ELBO.fit][0.50s] iter=26 ELBO=-1181.63 acc=0.6133 homo=0.3737\n",
      "  5017 [VGM-ELBO.fit][0.52s] iter=27 ELBO=-1181.63 acc=0.6133 homo=0.3737\n",
      "  5035 [VGM-ELBO.fit][0.54s] iter=28 ELBO=-1181.63 acc=0.6133 homo=0.3737\n",
      "  5053 [VGM-ELBO.fit][0.56s] iter=29 ELBO=-1181.63 acc=0.6133 homo=0.3737\n",
      "  5076 [VGM-ELBO.fit][0.58s] iter=30 ELBO=-1181.63 acc=0.6133 homo=0.3737\n",
      "  5097 [VGM-ELBO.fit][0.60s] iter=31 ELBO=-1181.63 acc=0.6133 homo=0.3737\n",
      "  5112 [VGM-ELBO.fit][0.62s] iter=32 ELBO=-1181.63 acc=0.6133 homo=0.3737\n",
      "  5128 [VGM-ELBO.fit][0.64s] iter=33 ELBO=-1181.63 acc=0.6133 homo=0.3737\n",
      "  5148 [VGM-ELBO.fit][0.66s] iter=34 ELBO=-1181.63 acc=0.6133 homo=0.3737\n",
      "  5167 [VGM-ELBO.fit][0.67s] iter=35 ELBO=-1181.63 acc=0.6133 homo=0.3737\n",
      "  5184 [VGM-ELBO.fit][0.69s] iter=36 ELBO=-1181.63 acc=0.6133 homo=0.3737\n",
      "  5186 [VGM-ELBO.fit] Converged due to no change in parameters.\n"
     ]
    }
   ],
   "source": [
    "best_allocations_std = vgmm0.fit(x_train, callback_iter=callback_iter,\n",
    "            min_niter=MIN_NITER, max_niter=MAX_NITER, noimprov_niter=NOIMPROV_NITER,\n",
    "            batch_size=EVAL_BATCH_SIZE, e_batch_size=E_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5231 Storing baseline results to GMVI_p_5_1.csv_baseline\n"
     ]
    }
   ],
   "source": [
    "results_pd = pd.DataFrame(RESULTS).rename(columns=dict(enumerate(COLS)))\n",
    "for name, val in zip(CFGNAMES, CFG):\n",
    "    results_pd[name] = str(val)\n",
    "logger.info(\"Storing baseline results to %s_baseline\" % OUT)\n",
    "results_pd.to_csv(OUT+\"_baseline\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5249 Clusters' sums using the standard VI:\n",
      "[2.08403e+02 4.00000e-03 9.15930e+01]\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Clusters' sums using the standard VI:\\n%s\" % np.round(np.sum(best_allocations_std, 0), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if VISUALIZATIONS:\n",
    "    try:\n",
    "        plt.scatter(x_train[:, 0], x_train[:, 1], c=vgmm0.classify(x_train))\n",
    "        plt.contour(x0, x1, vgmm0.pdf(x).reshape(100, 100))\n",
    "        plt.xlim(-R*2, R*2, 100)\n",
    "        plt.ylim(-R*2, R*2, 100)\n",
    "        plt.gca().set_aspect('equal', adjustable='box')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        logger.warn(\"Plotting failed: %s\" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration & results recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG += [float(-vgmm0.elbo(x_train, batch_size=EVAL_BATCH_SIZE)),\n",
    "        np.sum(np.sum(best_allocations_std, 0)>CLUSTER_MIN_WEIGHT),\n",
    "        acc(vgmm0.r, z_train)]\n",
    "CFGNAMES += [\"REFERENCE_LOSS\", \"REFERENCE_RECOVERED_NUM_CLUSTERS\", \"REFERENCE_ACCURRACY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _store_results(RESULTS, COLS, CFG, CFGNAMES, OUT):\n",
    "    results_pd = pd.DataFrame(RESULTS).rename(columns=dict(enumerate(COLS)))\n",
    "    for name, val in zip(CFGNAMES, CFG):\n",
    "        results_pd[name] = str(val)\n",
    "\n",
    "    logger.info(\"Writing %i data rows to: %s\" % (len(RESULTS), OUT))\n",
    "    results_pd.to_csv(OUT, header=True, index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimal_matching(mu0, allocations0, muf, allocationsf):    \n",
    "    # non-empty clusters according to the standard approach\n",
    "    retained_clusters = np.sum(allocations0, 0) > CLUSTER_MIN_WEIGHT\n",
    "    nonempty_nclusters = sum(retained_clusters)\n",
    "    # most-populated and least-populated clusters according to flow-based approach\n",
    "    cno2weight = enumerate(np.sum(allocationsf, 0))\n",
    "    cno2weight = sorted(cno2weight, key=lambda k2v: -k2v[1])\n",
    "    cno2weight = cno2weight[ : nonempty_nclusters]\n",
    "    heaviest_clusters_nos = [cno for cno, weight in cno2weight]\n",
    "    all_clusters_nos = set(range(allocationsf.shape[1]))\n",
    "    lightest_clusters_nos = sorted(all_clusters_nos - set(heaviest_clusters_nos))\n",
    "    \n",
    "    # reordering: empty clusters are moved to the end\n",
    "    reordering_std = list(np.nonzero(retained_clusters)[0]) + \\\n",
    "                     list(np.nonzero(~retained_clusters)[0])\n",
    "    mu0 = mu0[reordering_std, : ]\n",
    "    allocations0 = allocations0[ : , reordering_std]\n",
    "    \n",
    "    reordering_flows = heaviest_clusters_nos+lightest_clusters_nos        \n",
    "    muf = muf[reordering_flows, : ]  \n",
    "    allocationsf = allocationsf[ : , reordering_flows]\n",
    "                    \n",
    "    # matching between clusters (match centers of non-empty ones)\n",
    "    matching_order = gmvi.minimal_matching(mu0[ : nonempty_nclusters, : ], \n",
    "                                           muf[ : nonempty_nclusters, : ])\n",
    "    matching_order = list(matching_order)+sorted(all_clusters_nos-set(matching_order))\n",
    "    muf = muf[matching_order]\n",
    "    allocationsf = allocationsf[ : , matching_order] \n",
    "    \n",
    "    return mu0, allocations0, muf, allocationsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = []        \n",
    "COLS = [\"wall_time\", \"time\", \"iteration\", \"temp\", \"loss\", \"kl\", \"accurracy\", \"cdists\", \"rec_nclusters\"]\n",
    "\n",
    "start_time = time.time()\n",
    "callbacks_total_time = 0.\n",
    "def _callback(vgmmf, step_no, elbo):\n",
    "    global callbacks_total_time\n",
    "    callback_start_time = time.time()\n",
    "    gc.collect()\n",
    "    \n",
    "    # extract params\n",
    "    mu0, allocations0  = vgmm0.mu, best_allocations_std    \n",
    "    muf, allocationsf  = vgmmf.mu, vgmmf.r         \n",
    "    mu0, allocations0, muf, allocationsf = \\\n",
    "        minimal_matching(mu0, allocations0, muf, allocationsf) # match params\n",
    "    \n",
    "    # how many existing clusters\n",
    "    nonempty_nclusters = sum(np.sum(allocations0, 0)>CLUSTER_MIN_WEIGHT)\n",
    "    recovered_nclusters = np.sum(np.sum(allocationsf, 0)>CLUSTER_MIN_WEIGHT)\n",
    "    \n",
    "    # discrepancy between centers\n",
    "    between_centers_dists = np.sqrt( np.sum( (mu0-muf)**2, -1) )\n",
    "    between_centers_dists = between_centers_dists[ : nonempty_nclusters] # only non-empty\n",
    "    centers_mean_dist = np.mean(between_centers_dists)    \n",
    "    \n",
    "    kl_mc = float('nan') # ignored\n",
    "    \n",
    "    # how close we are to the true labels\n",
    "    accurracy = acc(allocationsf, z_train)\n",
    "    homogenity = sklearn.metrics.homogeneity_score(z_train, np.argmax(allocationsf, 1))\n",
    "    \n",
    "    logger.info((\"\"\"[VGMF.fit][%.2fs] step=%s. Elbo=%.2f KL=%.2f acc=%.4f homo=%.4f \n",
    "                     Temp=%.3f Avg-Dist-Mus:%.2f Rec-NClust:%s (min-weight=%.1f)\"\"\") % \\\n",
    "                (time.time()-start_time, step_no, \n",
    "                 elbo, kl_mc, accurracy, homogenity, \n",
    "                 vgmmf.temperature, centers_mean_dist, recovered_nclusters, \n",
    "                 min(np.sum(allocationsf, 0)), )\n",
    "               )\n",
    "    \n",
    "    callbacks_total_time += time.time()-callback_start_time        \n",
    "    wall_time = time.time()-start_time\n",
    "    RESULTS.append( (wall_time, wall_time-callbacks_total_time,  \n",
    "                     step_no, vgmmf.temperature, \n",
    "                     float(-elbo), float(kl_mc), accurracy,\n",
    "                     centers_mean_dist, recovered_nclusters,) )\n",
    "    \n",
    "    #_store_results(RESULTS, COLS, CFG, CFGNAMES, OUT)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximating family: bases and flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5347 FLOWS_K = 3\n",
      "  5351 [yield_probabilities_delta] WARNING: \n",
      "                       There is too many combinations of variables and categories! \n",
      "                       Generating diagonal and then random instead of all possible!\n"
     ]
    }
   ],
   "source": [
    "M, B = x_train.shape[0], B\n",
    "if FLOWS_K is None: FLOWS_K = K\n",
    "logger.info(\"FLOWS_K = %s\" % FLOWS_K)\n",
    "\n",
    "base = base_constructors.create_categorical_blocks(M, FLOWS_K, B, BASE_SPECIFICATION, \n",
    "                                                independent_variables=FACTORIZED_BASE); \n",
    "\n",
    "\n",
    "flow = flows_mixture.DiscreteFlowsMixture(M, FLOWS_K, B, temperature=BASE_TEMP,\n",
    "                     components_specification=[(FLOW_TYPE, M) for _ in range(B)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5426 optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f1bec5bab90> lr=0.1\n"
     ]
    }
   ],
   "source": [
    "OPTIMIZERS = {\"RMS\": tf.keras.optimizers.RMSprop,\n",
    "              \"ADAM\": tf.keras.optimizers.Adam}\n",
    "if OPTIMIZER not in OPTIMIZERS: raise ValueError(\"Unknown optimizer!\")\n",
    "optimizer_class = OPTIMIZERS[OPTIMIZER]\n",
    "optimizer = optimizer_class(learning_rate=LR)\n",
    "\n",
    "logger.info(\"optimizer=%s lr=%s\" % (optimizer, LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5437 VI inference type: <inference.VariationalInference object at 0x7f1bec592050>\n"
     ]
    }
   ],
   "source": [
    "ID2INFERENCE = {\n",
    "    0: inference.VariationalInference,\n",
    "    1: inference.BoostingVariationalInference,\n",
    "}\n",
    "inference_class = ID2INFERENCE[INFERENCE]\n",
    "\n",
    "vi = inference_class(base=base, flow=flow, \n",
    " optimizer=optimizer, nsamples=NSAMPLES, \n",
    " max_niter=E_NITER, noimprov_niter=E_NOIMPROV_NITER, min_niter=E_MIN_NITER)\n",
    "    \n",
    "logger.info(\"VI inference type: %s\" % vi)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational EM with Flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_profiling.reset()\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5458 vgmmf = VariationalGaussianMixtureFlows(\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vgmf_class = gmvi.VariationalGaussianMixtureFlows if E_HYBRID_ELBO else gmvi.VariationalGaussianMixtureFlowsSamples\n",
    "vgmmf = vgmf_class(inference=vi, n_components=K, elbo_nsamples=EVAL_NSAMPLES, initialization=INIT)\n",
    "logger.info(\"vgmmf = %s\" % vgmmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_annealing = lambda step_no, iteration: \\\n",
    "  max(BASE_TEMP*np.exp(-ANNEAL_RATE*step_no)*np.exp(-E_ANNEAL_RATE*iteration), MIN_TEMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5604 [VGMF.fit][0.16s] step=-1. Elbo=-196974.37 KL=nan acc=0.3667 homo=0.0035 \n",
      "                     Temp=10.000 Avg-Dist-Mus:2.34 Rec-NClust:3 (min-weight=99.8)\n",
      " 42779 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      " 43210 [VGMF.fit][37.76s] step=0. Elbo=-1297.33 KL=nan acc=0.5300 homo=0.1876 \n",
      "                     Temp=2.808 Avg-Dist-Mus:0.74 Rec-NClust:3 (min-weight=16.8)\n",
      "128374 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "128767 [VGMF.fit][123.32s] step=1. Elbo=-1238.42 KL=nan acc=0.5833 homo=0.2842 \n",
      "                     Temp=0.308 Avg-Dist-Mus:0.51 Rec-NClust:3 (min-weight=12.2)\n",
      "183453 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "183842 [VGMF.fit][178.40s] step=2. Elbo=-1216.28 KL=nan acc=0.6033 homo=0.3383 \n",
      "                     Temp=1.395 Avg-Dist-Mus:0.34 Rec-NClust:3 (min-weight=9.2)\n",
      "256688 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "257202 [VGMF.fit][251.76s] step=3. Elbo=-1209.12 KL=nan acc=0.6100 homo=0.3696 \n",
      "                     Temp=0.633 Avg-Dist-Mus:0.25 Rec-NClust:3 (min-weight=7.7)\n",
      "318119 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "318499 [VGMF.fit][313.05s] step=4. Elbo=-1203.57 KL=nan acc=0.6100 homo=0.3680 \n",
      "                     Temp=1.044 Avg-Dist-Mus:0.17 Rec-NClust:3 (min-weight=7.7)\n",
      "346254 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "346680 [VGMF.fit][341.23s] step=5. Elbo=-1203.24 KL=nan acc=0.6100 homo=0.3680 \n",
      "                     Temp=5.886 Avg-Dist-Mus:0.15 Rec-NClust:3 (min-weight=7.4)\n",
      "364958 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "365368 [VGMF.fit][359.92s] step=6. Elbo=-1202.57 KL=nan acc=0.6100 homo=0.3780 \n",
      "                     Temp=3.430 Avg-Dist-Mus:0.14 Rec-NClust:3 (min-weight=7.1)\n",
      "388911 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "389273 [VGMF.fit][383.83s] step=7. Elbo=-1200.69 KL=nan acc=0.6100 homo=0.3680 \n",
      "                     Temp=5.827 Avg-Dist-Mus:0.13 Rec-NClust:3 (min-weight=7.0)\n",
      "412943 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "413335 [VGMF.fit][407.89s] step=8. Elbo=-1200.18 KL=nan acc=0.6167 homo=0.3838 \n",
      "                     Temp=5.655 Avg-Dist-Mus:0.12 Rec-NClust:3 (min-weight=6.8)\n",
      "429498 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "430128 [VGMF.fit][424.68s] step=9. Elbo=-1199.09 KL=nan acc=0.6133 homo=0.3758 \n",
      "                     Temp=3.329 Avg-Dist-Mus:0.11 Rec-NClust:3 (min-weight=7.0)\n",
      "464916 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "465328 [VGMF.fit][459.88s] step=10. Elbo=-1198.43 KL=nan acc=0.6100 homo=0.3657 \n",
      "                     Temp=4.025 Avg-Dist-Mus:0.10 Rec-NClust:3 (min-weight=6.8)\n",
      "483594 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "483974 [VGMF.fit][478.53s] step=11. Elbo=-1198.52 KL=nan acc=0.6133 homo=0.3859 \n",
      "                     Temp=3.263 Avg-Dist-Mus:0.11 Rec-NClust:3 (min-weight=6.5)\n",
      "522658 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "523093 [VGMF.fit][517.65s] step=12. Elbo=-1198.20 KL=nan acc=0.6100 homo=0.3680 \n",
      "                     Temp=2.165 Avg-Dist-Mus:0.11 Rec-NClust:3 (min-weight=6.0)\n",
      "561266 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "561624 [VGMF.fit][556.18s] step=13. Elbo=-1198.42 KL=nan acc=0.6100 homo=0.3780 \n",
      "                     Temp=2.417 Avg-Dist-Mus:0.11 Rec-NClust:3 (min-weight=5.8)\n",
      "576918 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "577298 [VGMF.fit][571.85s] step=14. Elbo=-1199.28 KL=nan acc=0.6100 homo=0.3680 \n",
      "                     Temp=3.166 Avg-Dist-Mus:0.11 Rec-NClust:3 (min-weight=5.5)\n",
      "592809 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "593165 [VGMF.fit][587.72s] step=15. Elbo=-1199.00 KL=nan acc=0.6133 homo=0.3758 \n",
      "                     Temp=3.135 Avg-Dist-Mus:0.11 Rec-NClust:3 (min-weight=5.7)\n",
      "610273 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "610640 [VGMF.fit][605.20s] step=16. Elbo=-1198.75 KL=nan acc=0.6133 homo=0.3859 \n",
      "                     Temp=3.104 Avg-Dist-Mus:0.10 Rec-NClust:3 (min-weight=6.1)\n",
      "625855 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "626212 [VGMF.fit][620.77s] step=17. Elbo=-1197.99 KL=nan acc=0.6133 homo=0.3859 \n",
      "                     Temp=3.073 Avg-Dist-Mus:0.10 Rec-NClust:3 (min-weight=5.7)\n",
      "641962 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "642348 [VGMF.fit][636.90s] step=18. Elbo=-1197.97 KL=nan acc=0.6133 homo=0.3859 \n",
      "                     Temp=3.042 Avg-Dist-Mus:0.10 Rec-NClust:3 (min-weight=5.6)\n",
      "658539 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "658909 [VGMF.fit][653.46s] step=19. Elbo=-1198.45 KL=nan acc=0.6100 homo=0.3780 \n",
      "                     Temp=8.106 Avg-Dist-Mus:0.11 Rec-NClust:3 (min-weight=5.6)\n",
      "674100 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "674515 [VGMF.fit][669.07s] step=20. Elbo=-1198.26 KL=nan acc=0.6100 homo=0.3680 \n",
      "                     Temp=2.982 Avg-Dist-Mus:0.11 Rec-NClust:3 (min-weight=4.9)\n",
      "690002 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "690401 [VGMF.fit][684.96s] step=21. Elbo=-1198.52 KL=nan acc=0.6133 homo=0.3758 \n",
      "                     Temp=2.952 Avg-Dist-Mus:0.10 Rec-NClust:3 (min-weight=5.3)\n",
      "705933 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "706288 [VGMF.fit][700.84s] step=22. Elbo=-1197.96 KL=nan acc=0.6133 homo=0.3758 \n",
      "                     Temp=2.923 Avg-Dist-Mus:0.10 Rec-NClust:3 (min-weight=4.7)\n",
      "721638 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "722018 [VGMF.fit][716.57s] step=23. Elbo=-1199.07 KL=nan acc=0.6133 homo=0.3758 \n",
      "                     Temp=2.894 Avg-Dist-Mus:0.11 Rec-NClust:3 (min-weight=4.4)\n",
      "737170 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "737526 [VGMF.fit][732.08s] step=24. Elbo=-1199.10 KL=nan acc=0.6100 homo=0.3680 \n",
      "                     Temp=2.865 Avg-Dist-Mus:0.11 Rec-NClust:3 (min-weight=5.1)\n",
      "752699 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "753069 [VGMF.fit][747.62s] step=25. Elbo=-1198.12 KL=nan acc=0.6133 homo=0.3859 \n",
      "                     Temp=2.837 Avg-Dist-Mus:0.10 Rec-NClust:3 (min-weight=4.4)\n",
      "768990 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "769366 [VGMF.fit][763.92s] step=26. Elbo=-1198.17 KL=nan acc=0.6133 homo=0.3758 \n",
      "                     Temp=7.558 Avg-Dist-Mus:0.11 Rec-NClust:3 (min-weight=3.6)\n",
      "804420 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "804812 [VGMF.fit][799.37s] step=27. Elbo=-1197.36 KL=nan acc=0.6100 homo=0.3680 \n",
      "                     Temp=2.982 Avg-Dist-Mus:0.12 Rec-NClust:3 (min-weight=2.8)\n",
      "843413 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "843832 [VGMF.fit][838.39s] step=28. Elbo=-1197.42 KL=nan acc=0.6133 homo=0.3859 \n",
      "                     Temp=2.780 Avg-Dist-Mus:0.11 Rec-NClust:3 (min-weight=2.8)\n",
      "862441 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "862837 [VGMF.fit][857.39s] step=29. Elbo=-1197.17 KL=nan acc=0.6133 homo=0.3758 \n",
      "                     Temp=7.189 Avg-Dist-Mus:0.11 Rec-NClust:3 (min-weight=3.0)\n",
      "887329 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "888154 [VGMF.fit][882.71s] step=30. Elbo=-1197.35 KL=nan acc=0.6133 homo=0.3758 \n",
      "                     Temp=2.698 Avg-Dist-Mus:0.11 Rec-NClust:3 (min-weight=2.6)\n",
      "921140 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "921880 [VGMF.fit][916.43s] step=31. Elbo=-1196.87 KL=nan acc=0.6133 homo=0.3758 \n",
      "                     Temp=2.671 Avg-Dist-Mus:0.11 Rec-NClust:3 (min-weight=2.1)\n",
      "983182 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "983895 [VGMF.fit][978.45s] step=32. Elbo=-1196.42 KL=nan acc=0.6100 homo=0.3780 \n",
      "                     Temp=2.753 Avg-Dist-Mus:0.12 Rec-NClust:3 (min-weight=2.0)\n",
      "1032172 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1032941 [VGMF.fit][1027.50s] step=33. Elbo=-1197.03 KL=nan acc=0.6100 homo=0.3680 \n",
      "                     Temp=4.190 Avg-Dist-Mus:0.12 Rec-NClust:3 (min-weight=2.0)\n",
      "1087475 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "1088211 [VGMF.fit][1082.77s] step=34. Elbo=-1196.32 KL=nan acc=0.6133 homo=0.3859 \n",
      "                     Temp=3.499 Avg-Dist-Mus:0.12 Rec-NClust:3 (min-weight=1.7)\n",
      "1119885 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "1120584 [VGMF.fit][1115.14s] step=35. Elbo=-1195.96 KL=nan acc=0.6133 homo=0.3859 \n",
      "                     Temp=7.047 Avg-Dist-Mus:0.12 Rec-NClust:3 (min-weight=1.6)\n",
      "1152633 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "1153364 [VGMF.fit][1147.92s] step=36. Elbo=-1196.02 KL=nan acc=0.6100 homo=0.3780 \n",
      "                     Temp=2.541 Avg-Dist-Mus:0.12 Rec-NClust:3 (min-weight=1.9)\n",
      "1190018 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "1190767 [VGMF.fit][1185.32s] step=37. Elbo=-1195.85 KL=nan acc=0.6133 homo=0.3859 \n",
      "                     Temp=5.769 Avg-Dist-Mus:0.12 Rec-NClust:3 (min-weight=1.6)\n",
      "1223291 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "1224021 [VGMF.fit][1218.58s] step=38. Elbo=-1195.53 KL=nan acc=0.6100 homo=0.3780 \n",
      "                     Temp=2.491 Avg-Dist-Mus:0.12 Rec-NClust:3 (min-weight=1.7)\n",
      "1255188 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "1255892 [VGMF.fit][1250.45s] step=39. Elbo=-1196.39 KL=nan acc=0.6133 homo=0.3758 \n",
      "                     Temp=2.466 Avg-Dist-Mus:0.11 Rec-NClust:3 (min-weight=2.0)\n",
      "1287817 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "1288537 [VGMF.fit][1283.09s] step=40. Elbo=-1196.21 KL=nan acc=0.6133 homo=0.3859 \n",
      "                     Temp=2.441 Avg-Dist-Mus:0.11 Rec-NClust:3 (min-weight=2.0)\n",
      "1320027 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "1320783 [VGMF.fit][1315.34s] step=41. Elbo=-1196.17 KL=nan acc=0.6133 homo=0.3859 \n",
      "                     Temp=2.417 Avg-Dist-Mus:0.11 Rec-NClust:3 (min-weight=2.2)\n",
      "1352664 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "1353377 [VGMF.fit][1347.93s] step=42. Elbo=-1196.51 KL=nan acc=0.6100 homo=0.3780 \n",
      "                     Temp=2.393 Avg-Dist-Mus:0.11 Rec-NClust:3 (min-weight=2.5)\n",
      "1384440 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "1385174 [VGMF.fit][1379.73s] step=43. Elbo=-1196.34 KL=nan acc=0.6133 homo=0.3758 \n",
      "                     Temp=2.369 Avg-Dist-Mus:0.10 Rec-NClust:3 (min-weight=2.4)\n",
      "1417438 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "1418206 [VGMF.fit][1412.76s] step=44. Elbo=-1196.46 KL=nan acc=0.6100 homo=0.3780 \n",
      "                     Temp=2.346 Avg-Dist-Mus:0.11 Rec-NClust:3 (min-weight=2.1)\n",
      "1449857 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "1450599 [VGMF.fit][1445.15s] step=45. Elbo=-1196.25 KL=nan acc=0.6133 homo=0.3859 \n",
      "                     Temp=2.322 Avg-Dist-Mus:0.11 Rec-NClust:3 (min-weight=1.9)\n",
      "1482060 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "1482882 [VGMF.fit][1477.44s] step=46. Elbo=-1196.07 KL=nan acc=0.6133 homo=0.3859 \n",
      "                     Temp=2.299 Avg-Dist-Mus:0.11 Rec-NClust:3 (min-weight=1.9)\n",
      "1514114 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "1514889 [VGMF.fit][1509.44s] step=47. Elbo=-1196.07 KL=nan acc=0.6133 homo=0.3758 \n",
      "                     Temp=2.276 Avg-Dist-Mus:0.10 Rec-NClust:3 (min-weight=2.2)\n",
      "1554598 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "1555374 [VGMF.fit][1549.93s] step=48. Elbo=-1195.44 KL=nan acc=0.6133 homo=0.3758 \n",
      "                     Temp=4.724 Avg-Dist-Mus:0.11 Rec-NClust:3 (min-weight=1.6)\n",
      "1586919 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "1587686 [VGMF.fit][1582.24s] step=49. Elbo=-1195.44 KL=nan acc=0.6100 homo=0.3680 \n",
      "                     Temp=2.231 Avg-Dist-Mus:0.11 Rec-NClust:3 (min-weight=1.6)\n",
      "1647414 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "1648112 [VGMF.fit][1642.67s] step=50. Elbo=-1194.90 KL=nan acc=0.6133 homo=0.3859 \n",
      "                     Temp=2.466 Avg-Dist-Mus:0.11 Rec-NClust:3 (min-weight=1.5)\n",
      "1738445 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "1739132 [VGMF.fit][1733.69s] step=51. Elbo=-1194.63 KL=nan acc=0.6100 homo=0.3680 \n",
      "                     Temp=0.916 Avg-Dist-Mus:0.11 Rec-NClust:3 (min-weight=1.4)\n",
      "1770951 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "1771729 [VGMF.fit][1766.28s] step=52. Elbo=-1194.72 KL=nan acc=0.6100 homo=0.3780 \n",
      "                     Temp=2.165 Avg-Dist-Mus:0.10 Rec-NClust:3 (min-weight=1.4)\n",
      "1802981 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "1803747 [VGMF.fit][1798.30s] step=53. Elbo=-1195.12 KL=nan acc=0.6100 homo=0.3680 \n",
      "                     Temp=2.144 Avg-Dist-Mus:0.10 Rec-NClust:3 (min-weight=1.6)\n",
      "1837224 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "1837982 [VGMF.fit][1832.54s] step=54. Elbo=-1195.70 KL=nan acc=0.6100 homo=0.3680 \n",
      "                     Temp=2.122 Avg-Dist-Mus:0.10 Rec-NClust:3 (min-weight=1.9)\n",
      "1869174 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "1869905 [VGMF.fit][1864.46s] step=55. Elbo=-1195.31 KL=nan acc=0.6133 homo=0.3758 \n",
      "                     Temp=2.101 Avg-Dist-Mus:0.10 Rec-NClust:3 (min-weight=1.7)\n",
      "1901436 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "1902128 [VGMF.fit][1896.68s] step=56. Elbo=-1194.99 KL=nan acc=0.6100 homo=0.3657 \n",
      "                     Temp=2.080 Avg-Dist-Mus:0.10 Rec-NClust:3 (min-weight=1.7)\n",
      "1933766 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "1934502 [VGMF.fit][1929.06s] step=57. Elbo=-1195.27 KL=nan acc=0.6100 homo=0.3680 \n",
      "                     Temp=2.060 Avg-Dist-Mus:0.10 Rec-NClust:3 (min-weight=1.8)\n",
      "1966007 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "1966778 [VGMF.fit][1961.33s] step=58. Elbo=-1195.39 KL=nan acc=0.6133 homo=0.3758 \n",
      "                     Temp=2.039 Avg-Dist-Mus:0.10 Rec-NClust:3 (min-weight=2.0)\n",
      "1998343 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "1999050 [VGMF.fit][1993.60s] step=59. Elbo=-1195.20 KL=nan acc=0.6133 homo=0.3758 \n",
      "                     Temp=2.019 Avg-Dist-Mus:0.10 Rec-NClust:3 (min-weight=1.8)\n",
      "2031007 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "2031698 [VGMF.fit][2026.25s] step=60. Elbo=-1195.19 KL=nan acc=0.6133 homo=0.3758 \n",
      "                     Temp=1.999 Avg-Dist-Mus:0.09 Rec-NClust:3 (min-weight=1.9)\n",
      "2063736 [VariationalInference.fit] No improvement in recent 100 iterations. Stop.\n",
      "2064511 [VGMF.fit][2059.07s] step=61. Elbo=-1195.09 KL=nan acc=0.6133 homo=0.3758 \n",
      "                     Temp=1.979 Avg-Dist-Mus:0.09 Rec-NClust:3 (min-weight=2.0)\n",
      "2064512 [VGM-ELBO.fit] Converged due to no improvement in last 10 iterations.\n"
     ]
    }
   ],
   "source": [
    "best_allocations_flows = vgmmf.fit(x_train, \n",
    "            min_niter=MIN_NITER, max_niter=MAX_NITER, noimprov_niter=NOIMPROV_NITER, \n",
    "            batch_size=EVAL_BATCH_SIZE, \n",
    "            e_batch_size=E_BATCH_SIZE, e_batch_drop_remainder=E_DROP_REMAINDER,\n",
    "            temperature_annealing=temperature_annealing, \n",
    "            callback_iter = _callback,            \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2064564 Writing 63 data rows to: GMVI_p_5_1.csv\n"
     ]
    }
   ],
   "source": [
    "_store_results(RESULTS, COLS, CFG, CFGNAMES, OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if VISUALIZATIONS:\n",
    "    try:\n",
    "        plt.scatter(x_train[:, 0], x_train[:, 1], c=np.argmax(best_allocations_flows, -1))\n",
    "        plt.contour(x0, x1, vgmmf.pdf(x).reshape(100, 100))\n",
    "        plt.xlim(-R*2, R*2, 100)\n",
    "        plt.ylim(-R*2, R*2, 100)\n",
    "        plt.gca().set_aspect('equal', adjustable='box')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        logger.warn(\"Plotting failed: %s\" % e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>func</th>\n",
       "      <th>count</th>\n",
       "      <th>total</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>q=.8</th>\n",
       "      <th>#max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DiscreteFlowsMixture.call</td>\n",
       "      <td>9350</td>\n",
       "      <td>321.855</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.045</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>DiscreteFlowsMixture.reverse</td>\n",
       "      <td>8730</td>\n",
       "      <td>251.742</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.038</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>FactorizedCategoricalMixture.sample_extm</td>\n",
       "      <td>9350</td>\n",
       "      <td>86.535</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.012</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>FactorizedIndependentCategoricalMixture.log_pr...</td>\n",
       "      <td>8730</td>\n",
       "      <td>52.493</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.008</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>VariationalGaussianMixtureFlows.variational_ex...</td>\n",
       "      <td>62</td>\n",
       "      <td>2051.281</td>\n",
       "      <td>32.157</td>\n",
       "      <td>33.085</td>\n",
       "      <td>15.415</td>\n",
       "      <td>90.879</td>\n",
       "      <td>38.243</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                func  count     total  median  \\\n",
       "0                          DiscreteFlowsMixture.call   9350   321.855   0.034   \n",
       "1                       DiscreteFlowsMixture.reverse   8730   251.742   0.028   \n",
       "2           FactorizedCategoricalMixture.sample_extm   9350    86.535   0.009   \n",
       "3  FactorizedIndependentCategoricalMixture.log_pr...   8730    52.493   0.006   \n",
       "4  VariationalGaussianMixtureFlows.variational_ex...     62  2051.281  32.157   \n",
       "\n",
       "     mean     min     max    q=.8  #max  \n",
       "0   0.034   0.014   0.092   0.045    44  \n",
       "1   0.029   0.011   0.083   0.038    18  \n",
       "2   0.009   0.004   0.035   0.012    10  \n",
       "3   0.006   0.002   0.029   0.008     4  \n",
       "4  33.085  15.415  90.879  38.243     2  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_profiling.get_report().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare allocations (first half cols are std, then flows):\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "0.6  0.4  0.0 | 0.8  0.2  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "0.9  0.1  0.0 | 1.0  0.0  0.0\n",
      "0.1  0.9  0.0 | 0.2  0.8  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "0.7  0.3  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "0.8  0.2  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "0.3  0.7  0.0 | 0.6  0.4  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "0.8  0.2  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "0.8  0.2  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "0.0  1.0  0.0 | 0.2  0.8  0.0\n",
      "0.0  1.0  0.0 | 0.0  0.8  0.2\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.0  0.8  0.2\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.1  0.9  0.0 | 0.2  0.8  0.0\n",
      "0.0  1.0  0.0 | 0.2  0.8  0.0\n",
      "0.0  1.0  0.0 | 0.0  0.8  0.2\n",
      "0.1  0.9  0.0 | 0.2  0.8  0.0\n",
      "0.1  0.9  0.0 | 0.2  0.8  0.0\n",
      "0.5  0.5  0.0 | 0.6  0.4  0.0\n",
      "0.0  1.0  0.0 | 0.2  0.8  0.0\n",
      "0.0  1.0  0.0 | 0.2  0.8  0.0\n",
      "0.3  0.7  0.0 | 0.4  0.6  0.0\n",
      "0.1  0.9  0.0 | 0.2  0.8  0.0\n",
      "0.5  0.5  0.0 | 0.8  0.2  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.2  0.8  0.0\n",
      "0.0  1.0  0.0 | 0.2  0.8  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.2  0.8  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.2  0.8  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.7  0.3  0.0 | 0.8  0.2  0.0\n",
      "0.2  0.8  0.0 | 0.2  0.8  0.0\n",
      "0.1  0.9  0.0 | 0.2  0.8  0.0\n",
      "0.8  0.2  0.0 | 0.8  0.2  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.2  0.8  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.0  0.8  0.2\n",
      "0.0  1.0  0.0 | 0.2  0.8  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "0.1  0.9  0.0 | 0.2  0.8  0.0\n",
      "0.6  0.4  0.0 | 0.8  0.2  0.0\n",
      "0.0  1.0  0.0 | 0.2  0.8  0.0\n",
      "0.6  0.4  0.0 | 0.8  0.2  0.0\n",
      "0.1  0.9  0.0 | 0.2  0.8  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.1  0.9  0.0 | 0.2  0.8  0.0\n",
      "0.0  1.0  0.0 | 0.2  0.8  0.0\n",
      "0.1  0.9  0.0 | 0.2  0.8  0.0\n",
      "0.9  0.1  0.0 | 1.0  0.0  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.2  0.8  0.0 | 0.2  0.8  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.1  0.9  0.0 | 0.2  0.8  0.0\n",
      "0.1  0.9  0.0 | 0.2  0.8  0.0\n",
      "0.0  1.0  0.0 | 0.2  0.8  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.2  0.8  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.2  0.8  0.0 | 0.2  0.8  0.0\n",
      "0.8  0.2  0.0 | 1.0  0.0  0.0\n",
      "0.3  0.7  0.0 | 0.6  0.4  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "0.8  0.2  0.0 | 0.8  0.2  0.0\n",
      "0.7  0.3  0.0 | 0.8  0.2  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.2  0.8  0.0\n",
      "0.0  1.0  0.0 | 0.2  0.8  0.0\n",
      "0.0  1.0  0.0 | 0.2  0.8  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.2  0.8  0.0\n",
      "0.6  0.4  0.0 | 0.8  0.2  0.0\n",
      "0.1  0.9  0.0 | 0.2  0.8  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.0  0.8  0.2\n",
      "0.0  1.0  0.0 | 0.2  0.8  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.2  0.8  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.1  0.9  0.0 | 0.2  0.8  0.0\n",
      "0.7  0.3  0.0 | 0.8  0.2  0.0\n",
      "0.9  0.1  0.0 | 0.8  0.2  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.1  0.9  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.0  0.8  0.2\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.0  1.0  0.0\n",
      "0.0  1.0  0.0 | 0.2  0.8  0.0\n",
      "0.0  1.0  0.0 | 0.0  0.8  0.2\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "0.8  0.2  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "0.9  0.1  0.0 | 1.0  0.0  0.0\n",
      "0.8  0.2  0.0 | 0.8  0.2  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "0.9  0.1  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "0.1  0.9  0.0 | 0.2  0.8  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "0.9  0.1  0.0 | 0.8  0.2  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "0.9  0.1  0.0 | 0.8  0.2  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 0.8  0.2  0.0\n",
      "0.9  0.1  0.0 | 0.8  0.2  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "0.4  0.6  0.0 | 0.4  0.6  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n",
      "1.0  0.0  0.0 | 1.0  0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Compare allocations (first half cols are std, then flows):\")    \n",
    "mu0, allocations0  = vgmm0.mu, best_allocations_std    \n",
    "muf, allocationsf  = vgmmf.mu, best_allocations_flows\n",
    "mu0, allocations0, muf, allocationsf = \\\n",
    "        minimal_matching(mu0, allocations0, muf, allocationsf) \n",
    "for i in range(allocations0.shape[0]):\n",
    "    row0, rowf = allocations0[i,:], allocationsf[i,:]\n",
    "    s = \"  \".join(\"%.1f\" % v for v in row0)+\" | \"+\"  \".join(\"%.1f\" % v for v in rowf)\n",
    "    print(s)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster means:\n",
      "standard:\n",
      "[[-0.88086553  0.4737298 ]\n",
      " [ 1.71336377 -1.15105518]\n",
      " [-0.08544704 -0.02469083]]\n",
      "flows:\n",
      "[[-0.80970073  0.45104052]\n",
      " [ 1.73312647 -1.25603988]\n",
      " [ 1.92622034 -0.29875795]]\n"
     ]
    }
   ],
   "source": [
    "print(\"cluster means:\\nstandard:\\n%s\\nflows:\\n%s\" % (mu0, muf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
