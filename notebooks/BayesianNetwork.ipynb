{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Learning of Posteriors for Discrete Bayesian Networks using Mixture of Discrete Normalizing Flows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Bayes network (BN) represents a joint distribution of random variables factorized according to a directed\n",
    "acyclic graph (DAG) that determines their conditional independence. For BNs with latent nodes determining their joint posterior is difficult even if the structure is known. For sufficiently small networks the true posterior can be evaluated by direct enumeration of all configurations, with exponential cost in the number of latent nodes. We use this as ground truth, and compare against approximated posteriors represented with MDNF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../mdnf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aux\n",
    "import time_profiling\n",
    "\n",
    "import base_constructors\n",
    "import flows_mixture\n",
    "import flows\n",
    "import prob_recovery\n",
    "import bayesian_networks\n",
    "import inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='%(relativeCreated)6d %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3477 TF version=2.2.0\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"TF version=%s\" % tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3494 parsing: <-f>\n"
     ]
    }
   ],
   "source": [
    "# can be run as a script with args in format KEY=VAL,KEY=[STRVAL],...\n",
    "args = aux.parse_script_args() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3525 Results output file: BN_AVI_bnets_asia_D(0.01)_01_8_1.csv\n"
     ]
    }
   ],
   "source": [
    "SEED = args.get(\"SEED\", 1) # fix randomness\n",
    "\n",
    "MODEL = args.get(\"MODEL\", \"bnets/asia.bif\")\n",
    "EVIDENCE = args.get(\"EVIDENCE\", \"asia-yes/xray-yes\")\n",
    "# MODEL = args.get(\"MODEL\", \"bnets/sachs.bif\")\n",
    "# EVIDENCE = args.get(\"EVIDENCE\", \"Akt-LOW\")\n",
    "# MODEL = args.get(\"MODEL\", \"bnets/hepar2.bif\")\n",
    "# EVIDENCE = args.get(\"EVIDENCE\", \"carcinoma-present\")\n",
    "\n",
    "EVIDENCE = aux.parse_dict(EVIDENCE, entries_separator=\"/\", key2val_separator=\"-\")  \n",
    "\n",
    "# num categories, None = select automatically from Bayesian Network\n",
    "K = args.get(\"K\", None) \n",
    "\n",
    "# see create_base_mixture in base_constructors.py for options\n",
    "BASE_SPECIFICATION = args.get(\"BASE_SPECIFICATION\", \"D(0.01)\") \n",
    "B = args.get(\"B\", 8) # how many flows in mixture\n",
    "FLOW_TYPE = args.get(\"FLOW_TYPE\", \"M\") # transformation type\n",
    "\n",
    "# structure of transformation network\n",
    "HIDDEN_LAYERS = args.get(\"HIDDEN_LAYERS\", 1) \n",
    "HIDDEN_NODES_PER_VARIABLE = args.get(\"HIDDEN_NODES_PER_VARIABLE\", 1)\n",
    "\n",
    "INFERENCE = args.get(\"INFERENCE\", 0) # 0=VIF, 1=BVIF/BVI\n",
    "TRAIN_FLOWS = bool(args.get(\"TRAIN_FLOWS\", 1)) # if 0 only weights will be trained (= BVI)\n",
    "\n",
    "OPTIMIZER = args.get(\"OPTIMIZER\", \"RMS\").upper()\n",
    "LR = args.get(\"LR\", 0.01)\n",
    "\n",
    "# ignored: used only if weights are optimized separately\n",
    "LR2 = args.get(\"LR2\", 0.1) \n",
    "SWITCH_NITER = args.get(\"SWITCH_NITER\", 40) \n",
    "\n",
    "NSAMPLES = args.get(\"NSAMPLES\", 100) # how many samples to estimate ELBO\n",
    "MAX_NITER = args.get(\"MAX_NITER\", 100) \n",
    "NOIMPROV_NITER = args.get(\"NOIMPROV_NITER\", 50) # stop if no improvement seen in niters\n",
    "\n",
    "# temperature settings\n",
    "BASE_TEMP = args.get(\"BASE_TEMP\", 0.1) \n",
    "ANNEAL_RATE = args.get(\"ANNEAL_RATE\", 0.0)\n",
    "MIN_TEMP = args.get(\"MIN_TEMP\", 0.001)\n",
    "\n",
    "# where to save results\n",
    "OUT = args.get(\"OUT\", \"BN_AVI_%s_%s_%s%s_%s_%s.csv\" % \\\n",
    "               (MODEL.replace(\"/\", \"_\").replace(\".bif\", \"\"), BASE_SPECIFICATION, \n",
    "                INFERENCE, int(TRAIN_FLOWS), B, SEED))\n",
    "logger.info(\"Results output file: %s\" % OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3539 CONFIGURATION:\n",
      " MODEL=bnets/asia.bif\n",
      " EVIDENCE=asia=yes xray=yes\n",
      " SEED=1\n",
      " BASE_SPECIFICATION=D(0.01)\n",
      " B=8\n",
      " FLOW_TYPE=M\n",
      " HIDDEN_NODES_PER_VARIABLE=1\n",
      " HIDDEN_LAYERS=1\n",
      " INFERENCE=0\n",
      " TRAIN_FLOWS=1\n",
      " OPTIMIZER=RMS\n",
      " LR=0.01\n",
      " LR2=0.1\n",
      " NSAMPLES=100\n",
      " MAX_NITER=100\n",
      " NOIMPROV_NITER=50\n",
      " SWITCH_NITER=40\n",
      " BASE_TEMP=0.1\n",
      " ANNEAL_RATE=0.0\n",
      " MIN_TEMP=0.001\n"
     ]
    }
   ],
   "source": [
    "# Store & print configuration\n",
    "CFG =      [MODEL, \" \".join(\"%s=%s\" % (k,v) for k,v in EVIDENCE.items()), SEED, \n",
    "            BASE_SPECIFICATION, B, FLOW_TYPE, \n",
    "            HIDDEN_NODES_PER_VARIABLE, HIDDEN_LAYERS,\n",
    "            int(INFERENCE), int(TRAIN_FLOWS),\n",
    "            OPTIMIZER, LR, LR2, \n",
    "            NSAMPLES, MAX_NITER, NOIMPROV_NITER, SWITCH_NITER,\n",
    "            BASE_TEMP, ANNEAL_RATE, MIN_TEMP]\n",
    "CFGNAMES = [\"MODEL\", \"EVIDENCE\", \"SEED\", \n",
    "            \"BASE_SPECIFICATION\", \"B\", \"FLOW_TYPE\", \n",
    "            \"HIDDEN_NODES_PER_VARIABLE\", \"HIDDEN_LAYERS\",\n",
    "            \"INFERENCE\", \"TRAIN_FLOWS\",\n",
    "            \"OPTIMIZER\", \"LR\", \"LR2\", \n",
    "            \"NSAMPLES\", \"MAX_NITER\", \"NOIMPROV_NITER\", \"SWITCH_NITER\",\n",
    "            \"BASE_TEMP\", \"ANNEAL_RATE\", \"MIN_TEMP\"]\n",
    "\n",
    "logger.info(\"CONFIGURATION:\\n \"+\"\\n \".join(\"%s=%s\" % (name, val) \n",
    "                                     for name, val in zip(CFGNAMES, CFG)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3551 optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f5c9a25cb10> optimizer_weights=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f5c9a25cad0>\n"
     ]
    }
   ],
   "source": [
    "OPTIMIZERS = {\"RMS\": tf.keras.optimizers.RMSprop,\n",
    "              \"ADAM\": tf.keras.optimizers.Adam}\n",
    "if OPTIMIZER not in OPTIMIZERS: raise ValueError(\"Unknown optimizer!\")\n",
    "optimizer_class = OPTIMIZERS[OPTIMIZER]\n",
    "optimizer = optimizer_class(learning_rate=LR)\n",
    "optimizer_weights = optimizer_class(learning_rate=LR2)\n",
    "logger.info(\"optimizer=%s optimizer_weights=%s\" % (optimizer, optimizer_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network & evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Bayesian network and fix evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7284 +-----------+------+\n",
      "| asia(yes) | 0.01 |\n",
      "+-----------+------+\n",
      "| asia(no)  | 0.99 |\n",
      "+-----------+------+\n",
      "  7285 +------------+------------+-----------+\n",
      "| smoke      | smoke(yes) | smoke(no) |\n",
      "+------------+------------+-----------+\n",
      "| bronc(yes) | 0.6        | 0.3       |\n",
      "+------------+------------+-----------+\n",
      "| bronc(no)  | 0.4        | 0.7       |\n",
      "+------------+------------+-----------+\n",
      "  7287 +-----------+-------------+------------+-------------+------------+\n",
      "| bronc     | bronc(yes)  | bronc(yes) | bronc(no)   | bronc(no)  |\n",
      "+-----------+-------------+------------+-------------+------------+\n",
      "| either    | either(yes) | either(no) | either(yes) | either(no) |\n",
      "+-----------+-------------+------------+-------------+------------+\n",
      "| dysp(yes) | 0.9         | 0.8        | 0.7         | 0.1        |\n",
      "+-----------+-------------+------------+-------------+------------+\n",
      "| dysp(no)  | 0.1         | 0.2        | 0.3         | 0.9        |\n",
      "+-----------+-------------+------------+-------------+------------+\n",
      "  7288 +-------------+-----------+-----------+----------+----------+\n",
      "| lung        | lung(yes) | lung(yes) | lung(no) | lung(no) |\n",
      "+-------------+-----------+-----------+----------+----------+\n",
      "| tub         | tub(yes)  | tub(no)   | tub(yes) | tub(no)  |\n",
      "+-------------+-----------+-----------+----------+----------+\n",
      "| either(yes) | 1.0       | 1.0       | 1.0      | 0.0      |\n",
      "+-------------+-----------+-----------+----------+----------+\n",
      "| either(no)  | 0.0       | 0.0       | 0.0      | 1.0      |\n",
      "+-------------+-----------+-----------+----------+----------+\n",
      "  7295 +-----------+------------+-----------+\n",
      "| smoke     | smoke(yes) | smoke(no) |\n",
      "+-----------+------------+-----------+\n",
      "| lung(yes) | 0.1        | 0.01      |\n",
      "+-----------+------------+-----------+\n",
      "| lung(no)  | 0.9        | 0.99      |\n",
      "+-----------+------------+-----------+\n",
      "  7299 +------------+-----+\n",
      "| smoke(yes) | 0.5 |\n",
      "+------------+-----+\n",
      "| smoke(no)  | 0.5 |\n",
      "+------------+-----+\n",
      "  7300 +----------+-----------+----------+\n",
      "| asia     | asia(yes) | asia(no) |\n",
      "+----------+-----------+----------+\n",
      "| tub(yes) | 0.05      | 0.01     |\n",
      "+----------+-----------+----------+\n",
      "| tub(no)  | 0.95      | 0.99     |\n",
      "+----------+-----------+----------+\n",
      "  7307 +-----------+-------------+------------+\n",
      "| either    | either(yes) | either(no) |\n",
      "+-----------+-------------+------------+\n",
      "| xray(yes) | 0.98        | 0.05       |\n",
      "+-----------+-------------+------------+\n",
      "| xray(no)  | 0.02        | 0.95       |\n",
      "+-----------+-------------+------------+\n",
      "  7311 [BayesianNetworkVI] 8 vars with max cardinality=2 => enumeration size=256\n"
     ]
    }
   ],
   "source": [
    "net = bayesian_networks.BayesianNetworkVI(EVIDENCE, MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model joint log-probability evaluation with the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prob = lambda sample: net.log_prob( net.set_evidence(sample) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If possible obtain posterior by enumeration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if net.enumeration_size < 10e6:\n",
    "    positions, probs = net.posteriors_via_enumeration()\n",
    "    TARGET = bayesian_networks.as_tensor(positions, probs)\n",
    "else:\n",
    "    TARGET = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recording configuration & results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _store_results(RESULTS, COLS, CFG, CFGNAMES, OUT):\n",
    "    results_pd = pd.DataFrame(RESULTS).rename(columns=dict(enumerate(COLS)))\n",
    "    for name, val in zip(CFGNAMES, CFG):\n",
    "        results_pd[name] = str(val)\n",
    "\n",
    "    logger.info(\"Writing %i data rows to: %s\" % (len(RESULTS), OUT))\n",
    "    results_pd.to_csv(OUT, header=True, index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = []\n",
    "\n",
    "# what to put into results    \n",
    "COLS = [\"wall_time\", \"time\", \"time_forward\", \"time_backward\",\n",
    "        \"C\", \"iteration\", \"temp\", \"loss\", \"kl\", \"best_loss\", \"best_kl\", \"kl2\"]   \n",
    "\n",
    "start_time = time.time()\n",
    "best_loss, best_kl = float(\"inf\"), float(\"inf\")\n",
    "\n",
    "def record_status(status, iteration, loss): # callback function\n",
    "    global best_loss, best_kl    \n",
    "    improved = loss < best_loss    \n",
    "    if not improved and iteration>10 and iteration%10!=0: return \n",
    "    \n",
    "    kl, kl2, _ = prob_recovery.kl_divergences(status.base, status.flow, TARGET)    \n",
    "    if improved: best_loss, best_kl = loss, kl\n",
    "    \n",
    "    try: C = status.C\n",
    "    except: C = \"\"\n",
    "    temp = status.flow.temperature\n",
    "    logger.info((\"[%.0fs](%s) %s:%i. loss=%.3f \" +\n",
    "           \"kl=%.2f (best: %.3f/%.2f) kl2=%.2f temp=%.4f\\n\\tmixing=%s\") % \\\n",
    "          (time.time() - start_time, (\"*\" if improved else \" \"), C, iteration, \n",
    "           loss, kl, best_loss, best_kl, kl2,\n",
    "           temp if temp is not None else float(\"nan\"),\n",
    "           str(np.round(status.base.mixing_probs,2))[:200]))\n",
    "    \n",
    "    RESULTS.append((time.time() - start_time,\n",
    "                    status.time_forward + status.time_backward, \n",
    "                    status.time_forward, status.time_backward,\n",
    "                    C, iteration, status.flow.temperature,\n",
    "                    loss, kl, best_loss, best_kl, kl2))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximating distribution: set bases and flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7451 N=6 K=2 B=8\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "if K is None: K = net.cardinality # set automatically\n",
    "N = net.N-len(EVIDENCE) \n",
    "if B is None or B<=0: B = K**N\n",
    "logger.info(\"N=%i K=%i B=%i\" % (N, K, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = base_constructors.create_categorical_blocks(N, K, B, BASE_SPECIFICATION)\n",
    "\n",
    "for i in range(len(base.components)):\n",
    "    logger.debug(\"base no%s:\\n%s\" % (i, np.round(base.components[i].probs, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TRAIN_FLOWS:\n",
    "    mixture_flows = [flows.DummyFlow(temperature=BASE_TEMP) for _ in range(B)]     \n",
    "elif FLOW_TYPE in [\"F\", \"FU\"]:\n",
    "    mixture_flows = [flows.DiscreteFlow(N,K, layers=[(FLOW_TYPE, None)]*HIDDEN_LAYERS) \n",
    "                     for _ in range(B)]\n",
    "else:\n",
    "    HIDDEN_NODES = int(N*HIDDEN_NODES_PER_VARIABLE) \n",
    "    mixture_flows = flows.parse_layers_specification([(FLOW_TYPE, [HIDDEN_NODES]*HIDDEN_LAYERS)]*B,\n",
    "                     N, K, temperature=BASE_TEMP)\n",
    "\n",
    "flow = flows_mixture.DiscreteFlowsMixture(N, K, B, flows=mixture_flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  \n",
      "  7576  Failed: Outer product currently implemented only for 2D and 3D arrays! -> Skipping...\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for i, d1 in enumerate(base.distributions):\n",
    "        logger.debug(\"probabilities of component no %i:\" % i)\n",
    "        logger.debug(np.round(d1.get_joint_probability_array(), 3))\n",
    "except Exception as e:\n",
    "    logger.warn(\" Failed: %s -> Skipping...\" % e)\n",
    "    pass\n",
    "\n",
    "#logger.info(\"Trainable variables:\\n %s\" % \"\\n \".join([v.name for v in flow.trainable_variables]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7599 VI inference type: <inference.VariationalInference object at 0x7f5c980ccc50>\n"
     ]
    }
   ],
   "source": [
    "ID2INFERENCE = {\n",
    "    0: inference.VariationalInference,\n",
    "    1: inference.BoostingVariationalInference,\n",
    "    2: inference.IterativeVariationalInference,\n",
    "    3: inference.BoostingVariationalInferenceAltering,\n",
    "    4: inference.BoostingVariationalInferenceAlteringIndep,\n",
    "}\n",
    "inference_class = ID2INFERENCE[INFERENCE]\n",
    "\n",
    "vi = inference_class(log_prob=log_prob, base=base, flow=flow, \n",
    " temperature_annealing=inference.TemperatureAnnealingExp(BASE_TEMP,ANNEAL_RATE,MIN_TEMP),\n",
    " nsamples=NSAMPLES, max_niter=MAX_NITER, noimprov_niter=NOIMPROV_NITER, \n",
    " optimizer=optimizer, optimizer_weights=optimizer_weights, switch_niter=SWITCH_NITER)\n",
    "    \n",
    "logger.info(\"VI inference type: %s\" % vi)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8045 [1s](*) :0. loss=23.168 kl=14.99 (best: 23.168/14.99) kl2=7.41 temp=0.1000\n",
      "\tmixing=[0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12]\n",
      "  8564 [1s](*) :1. loss=13.970 kl=9.07 (best: 13.970/9.07) kl2=6.60 temp=0.1000\n",
      "\tmixing=[0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12]\n",
      "  8940 [2s]( ) :2. loss=14.460 kl=9.72 (best: 13.970/9.07) kl2=5.63 temp=0.1000\n",
      "\tmixing=[0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12]\n",
      "  9284 [2s]( ) :3. loss=20.794 kl=11.79 (best: 13.970/9.07) kl2=7.21 temp=0.1000\n",
      "\tmixing=[0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12]\n",
      "  9623 [2s]( ) :4. loss=18.740 kl=10.46 (best: 13.970/9.07) kl2=6.68 temp=0.1000\n",
      "\tmixing=[0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12]\n",
      " 10104 [3s](*) :5. loss=8.900 kl=2.20 (best: 8.900/2.20) kl2=6.04 temp=0.1000\n",
      "\tmixing=[0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12]\n",
      " 10587 [3s](*) :6. loss=8.574 kl=1.96 (best: 8.574/1.96) kl2=5.70 temp=0.1000\n",
      "\tmixing=[0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12]\n",
      " 10966 [4s]( ) :7. loss=11.896 kl=5.44 (best: 8.574/1.96) kl2=6.11 temp=0.1000\n",
      "\tmixing=[0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12]\n",
      " 11469 [4s](*) :8. loss=8.133 kl=1.61 (best: 8.133/1.61) kl2=5.33 temp=0.1000\n",
      "\tmixing=[0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12]\n",
      " 11985 [5s]( ) :9. loss=8.341 kl=1.68 (best: 8.133/1.61) kl2=6.02 temp=0.1000\n",
      "\tmixing=[0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12]\n",
      " 12477 [5s](*) :10. loss=7.883 kl=1.42 (best: 7.883/1.42) kl2=5.26 temp=0.1000\n",
      "\tmixing=[0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12]\n",
      " 12950 [6s](*) :11. loss=7.798 kl=1.42 (best: 7.798/1.42) kl2=5.26 temp=0.1000\n",
      "\tmixing=[0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12]\n",
      " 14903 [7s](*) :16. loss=7.790 kl=1.19 (best: 7.790/1.19) kl2=5.51 temp=0.1000\n",
      "\tmixing=[0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12]\n",
      " 15358 [8s](*) :17. loss=7.675 kl=1.19 (best: 7.675/1.19) kl2=5.51 temp=0.1000\n",
      "\tmixing=[0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12]\n",
      " 16296 [9s]( ) :20. loss=7.817 kl=1.19 (best: 7.675/1.19) kl2=5.51 temp=0.1000\n",
      "\tmixing=[0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12]\n",
      " 17680 [10s](*) :24. loss=7.523 kl=1.19 (best: 7.523/1.19) kl2=5.52 temp=0.1000\n",
      "\tmixing=[0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12]\n",
      " 19503 [12s]( ) :30. loss=12.363 kl=5.35 (best: 7.523/1.19) kl2=5.99 temp=0.1000\n",
      "\tmixing=[0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12]\n",
      " 22691 [15s]( ) :40. loss=7.945 kl=1.32 (best: 7.523/1.19) kl2=5.76 temp=0.1000\n",
      "\tmixing=[0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12]\n",
      " 26032 [19s]( ) :50. loss=7.693 kl=1.32 (best: 7.523/1.19) kl2=5.76 temp=0.1000\n",
      "\tmixing=[0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12]\n",
      " 29406 [22s]( ) :60. loss=7.861 kl=1.41 (best: 7.523/1.19) kl2=6.24 temp=0.1000\n",
      "\tmixing=[0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12]\n",
      " 32476 [25s]( ) :70. loss=8.048 kl=1.41 (best: 7.523/1.19) kl2=6.24 temp=0.1000\n",
      "\tmixing=[0.12 0.12 0.12 0.12 0.12 0.12 0.12 0.12]\n",
      " 34127 [VariationalInference.fit] No improvement in recent 50 iterations. Stop.\n"
     ]
    }
   ],
   "source": [
    "total_niters = vi.fit(callback=record_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34151 Writing 21 data rows to: BN_AVI_bnets_asia_D(0.01)_01_8_1.csv\n"
     ]
    }
   ],
   "source": [
    "_store_results(RESULTS, COLS, CFG, CFGNAMES, OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34219 kl=1.185 kl2=5.524\n"
     ]
    }
   ],
   "source": [
    "if TARGET is not None:\n",
    "    base, flow = vi.best_base, vi.best_flow\n",
    "    kl, kl2, flow_output_probs = prob_recovery.kl_divergences(base, flow, TARGET)\n",
    "    logger.info(\"kl=%.3f kl2=%.3f\" % (kl, kl2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        func  count      total    median  \\\n",
      "0                  DiscreteFlowsMixture.call     76  11.137210  0.138255   \n",
      "1               DiscreteFlowsMixture.reverse     98   2.366740  0.021829   \n",
      "2  FactorizedCategoricalMixture.log_prob_ext     98   0.048434  0.000474   \n",
      "3   FactorizedCategoricalMixture.sample_extm     76   0.212890  0.002547   \n",
      "\n",
      "       mean       min       max      q=.8  #max  \n",
      "0  0.146542  0.126653  0.293996  0.157641     2  \n",
      "1  0.024150  0.018183  0.143198  0.025152     1  \n",
      "2  0.000494  0.000351  0.000907  0.000524     4  \n",
      "3  0.002801  0.002316  0.007165  0.002985     1  \n"
     ]
    }
   ],
   "source": [
    "print(time_profiling.get_report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
